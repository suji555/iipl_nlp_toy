{"cells":[{"metadata":{},"cell_type":"markdown","source":"## 0. GPU Setting"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nos.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \nos.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"","execution_count":1,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1. Data load"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\n\ntrain = pd.read_csv('../input/quora-insincere-questions-classification/train.csv')\ntest = pd.read_csv('../input/quora-insincere-questions-classification/test.csv')","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"                    qid                                      question_text  \\\n0  00002165364db923c7e6  How did Quebec nationalists see their province...   \n1  000032939017120e6e44  Do you have an adopted dog, how would you enco...   \n2  0000412ca6e4628ce2cf  Why does velocity affect time? Does velocity a...   \n3  000042bf85aa498cd78e  How did Otto von Guericke used the Magdeburg h...   \n4  0000455dfa3e01eae3af  Can I convert montra helicon D to a mountain b...   \n\n   target  \n0       0  \n1       0  \n2       0  \n3       0  \n4       0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>qid</th>\n      <th>question_text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00002165364db923c7e6</td>\n      <td>How did Quebec nationalists see their province...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000032939017120e6e44</td>\n      <td>Do you have an adopted dog, how would you enco...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0000412ca6e4628ce2cf</td>\n      <td>Why does velocity affect time? Does velocity a...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>000042bf85aa498cd78e</td>\n      <td>How did Otto von Guericke used the Magdeburg h...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0000455dfa3e01eae3af</td>\n      <td>Can I convert montra helicon D to a mountain b...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"                    qid                                      question_text\n0  0000163e3ea7c7a74cd7  Why do so many women become so rude and arroga...\n1  00002bd4fb5d505b9161  When should I apply for RV college of engineer...\n2  00007756b4a147d2b0b3  What is it really like to be a nurse practitio...\n3  000086e4b7e1c7146103                             Who are entrepreneurs?\n4  0000c4c3fbe8785a3090   Is education really making good people nowadays?","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>qid</th>\n      <th>question_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000163e3ea7c7a74cd7</td>\n      <td>Why do so many women become so rude and arroga...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00002bd4fb5d505b9161</td>\n      <td>When should I apply for RV college of engineer...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00007756b4a147d2b0b3</td>\n      <td>What is it really like to be a nurse practitio...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>000086e4b7e1c7146103</td>\n      <td>Who are entrepreneurs?</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0000c4c3fbe8785a3090</td>\n      <td>Is education really making good people nowadays?</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train[:30000]","execution_count":5,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\n\ndef alpha_num(text):\n    return re.sub(r'[^a-zA-z0-9\\s]', '', text)","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text_list = train['question_text'].str.lower().apply(alpha_num)\ntest_text_list = test['question_text'].str.lower().apply(alpha_num)","execution_count":7,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Train & validation split"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\n\nvalid_percent = 0.2\n\ndata_len = len(train)\nvalid_index = np.random.choice(range(data_len), int(data_len*valid_percent), replace=False)\ntrain_index = list(set(range(data_len)) - set(valid_index))\ntest_index = list(range(len(test)))\n\ntrain_text_list = [text_list[i] for i in train_index]\nvalid_text_list = [text_list[i] for i in valid_index]\nvalid_text_list = [test_text_list[i] for i in test_index]\ntrain_label_list = [train['target'].tolist()[i] for i in train_index]\nvalid_label_list = [train['target'].tolist()[i] for i in valid_index]","execution_count":8,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4. Parsing"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\n\nsave_path = './save'\n\nif not os.path.exists(save_path):\n    os.mkdir(save_path)","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sentencepiece as spm\n\nvocab_size = 12000\npad_idx = 0\nbos_idx = 1\neos_idx = 2\nunk_idx = 3\n\n# 1) Make Korean text to train vocab\nwith open(f'{save_path}/text.txt', 'w') as f:\n    for text in train_text_list:\n        f.write(f'{text}\\n')\n\n\n# 2) SentencePiece model training\nspm.SentencePieceProcessor()\nspm.SentencePieceTrainer.Train(\n    f'--input={save_path}/text.txt --model_prefix={save_path}/m_text '\n    f'--vocab_size={vocab_size} --character_coverage=0.9995 '\n    f'--model_type=bpe --split_by_whitespace=true '\n    f'--pad_id={pad_idx} --unk_id={unk_idx} '\n    f'--bos_id={bos_idx} --eos_id={eos_idx}'\n)\n\nvocab_list = list()\nwith open(f'{save_path}/m_text.vocab') as f:\n    for line in f:\n        vocab_list.append(line[:-1].split('\\t')[0])\nword2id_spm = {w: i for i, w in enumerate(vocab_list)}","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# SentencePiece model load\nspm_ = spm.SentencePieceProcessor()\nspm_.Load(f\"{save_path}/m_text.model\")\n\n# Tokenizing\ntrain_encoded_list = [[bos_idx] + spm_.EncodeAsIds(text) + [eos_idx] for text in train_text_list]\nvalid_encoded_list = [[bos_idx] + spm_.EncodeAsIds(text) + [eos_idx] for text in valid_text_list]\ntest_encoded_list = [[bos_idx] + spm_.EncodeAsIds(text) + [eos_idx] for text in test_text_list]","execution_count":11,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5. Custom dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nfrom torch.utils.data.dataset import Dataset\n\nclass CustomDataset(Dataset):\n    def __init__(self, src_list, trg_list, min_len=4, max_len=500):\n        data = list()\n        for src, trg in zip(src_list, trg_list):\n            if min_len <= len(src) <= max_len:\n                data.append((src, trg))\n\n        self.data = data\n        self.num_data = len(self.data)\n    \n    def __getitem__(self, index):\n        src, trg = self.data[index]\n        return src, trg\n\n    def __len__(self):\n        return self.num_data\n\nclass PadCollate:\n    def __init__(self, pad_index=0, dim=0):\n        self.dim = dim\n        self.pad_index = pad_index\n\n    def pad_collate(self, batch):\n        def pad_tensor(vec, max_len, dim):\n            pad_size = list(vec.shape)\n            pad_size[dim] = max_len - vec.size(dim)\n            return torch.cat([vec, torch.LongTensor(*pad_size).fill_(self.pad_index)], dim=dim)\n\n        def pack_sentence(sentences):\n            sentences_len = max(map(lambda x: len(x), sentences))\n            sentences = [pad_tensor(torch.LongTensor(seq), sentences_len, self.dim) for seq in sentences]\n            sentences = torch.cat(sentences)\n            sentences = sentences.view(-1, sentences_len)\n            return sentences\n\n        src, trg = zip(*batch)\n        return pack_sentence(src), torch.LongTensor(trg)\n\n    def __call__(self, batch):\n        return self.pad_collate(batch)","execution_count":12,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 6. DataLoader"},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch.utils.data import DataLoader\n\nbatch_size = 8\n\ndataset_dict = {\n    'train': CustomDataset(train_encoded_list, train_label_list, min_len=4, max_len=500),\n    'valid': CustomDataset(valid_encoded_list, valid_label_list, min_len=4, max_len=500)\n}\n\ndataloader_dict = {\n    'train': DataLoader(dataset_dict['train'], collate_fn=PadCollate(), drop_last=True,\n                        batch_size=batch_size, num_workers=4, shuffle=True, pin_memory=True),\n    'valid': DataLoader(dataset_dict['valid'], collate_fn=PadCollate(), drop_last=True,\n                        batch_size=batch_size, num_workers=4, shuffle=True, pin_memory=True)\n}\n\nprint(f'Total number of trainingsets  iterations - {len(dataset_dict[\"train\"])}, {len(dataloader_dict[\"train\"])}')","execution_count":13,"outputs":[{"output_type":"stream","text":"Total number of trainingsets  iterations - 24000, 3000\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## 7. Build model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch import nn\nfrom torch.nn import functional as F\n\nclass GRU(nn.Module):\n    def __init__(self, n_layers, hidden_dim, src_vocab_num, d_embedding=256, trg_num=2, dropout=0.5):\n\n        super(GRU, self).__init__()\n        \n        self.n_layers = n_layers\n        self.hidden_dim = hidden_dim\n\n        self.src_embedding = nn.Embedding(src_vocab_num, d_embedding, padding_idx=pad_idx)\n        self.dropout = nn.Dropout(dropout)\n        self.gru = nn.GRU(d_embedding, self.hidden_dim,\n                         num_layers=self.n_layers,\n                         batch_first=True)\n        self.linear = nn.Linear(self.hidden_dim, trg_num)\n        \n\n    def forward(self, src):\n\n        x = self.src_embedding(src)\n        h_0 = self._init_state(batch_size=x.size(0))\n        x, _ = self.gru(x, h_0)\n        h_t = x[:,-1,:]\n        self.dropout(h_t)\n        logit = self.linear(h_t)\n\n        return logit\n\n    def _init_state(self, batch_size=1):\n        weight = next(self.parameters()).data\n        return weight.new(self.n_layers, batch_size, self.hidden_dim).zero_()","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel = GRU(1, 256, vocab_size, d_embedding=256, trg_num=2, dropout=0.1)\nmodel.to(device)","execution_count":15,"outputs":[{"output_type":"execute_result","execution_count":15,"data":{"text/plain":"GRU(\n  (src_embedding): Embedding(12000, 256, padding_idx=0)\n  (dropout): Dropout(p=0.5, inplace=False)\n  (gru): GRU(256, 256, batch_first=True)\n  (linear): Linear(in_features=256, out_features=2, bias=True)\n)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## 8. Optimizer setting"},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch.optim as optim\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\n\nlr = 1e-2\n\noptimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=1e-5)\nscheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, \n                              patience=len(dataloader_dict['train'])/1.5)\ncriterion = nn.CrossEntropyLoss()","execution_count":16,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 9. Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"import time\nfrom torch.nn.utils import clip_grad_norm_\n\nnum_epoch = 5\n\nprint_freq = 1500\nbest_val_loss = None\n\nfor e in range(num_epoch):\n    start_time_e = time.time()\n    print(f'Model Fitting: [{e+1}/{num_epoch}]')\n    for phase in ['train', 'valid']:\n        if phase == 'train':\n            model.train()\n            freq = 0\n        if phase == 'valid':\n            model.eval()\n            val_loss = 0\n            val_acc = 0\n\n        for i, (src, trg) in enumerate(dataloader_dict[phase]):\n            # Optimizer setting\n            optimizer.zero_grad()\n\n            # Source, Target sentence setting\n            src = src.to(device)\n            trg = trg.to(device)\n\n            # Model / Calculate loss\n            with torch.set_grad_enabled(phase == 'train'):\n                predicted_logit = model(src)\n\n                # If phase train, then backward loss and step optimizer and scheduler\n                if phase == 'train':\n                    loss = criterion(predicted_logit, trg)\n                    loss.backward()\n                    clip_grad_norm_(model.parameters(), 5)\n                    optimizer.step()\n                    scheduler.step(loss)\n\n                    # Print loss value only training\n                    if freq == print_freq or freq == 0 or i == len(dataloader_dict['train']):\n                        total_loss = loss.item()\n                        _, predicted = predicted_logit.max(dim=1)\n                        accuracy = sum(predicted == trg).item() / predicted.size(0)\n                        print(\"[Epoch:%d][%d/%d] train_loss:%5.3f | Accuracy:%2.3f | lr:%1.6f | spend_time:%5.2fmin\"\n                                % (e+1, i, len(dataloader_dict['train']), total_loss, accuracy, \n                                optimizer.param_groups[0]['lr'], (time.time() - start_time_e) / 60))\n                        freq = 0\n                    freq += 1\n                if phase == 'valid':\n                    loss = F.cross_entropy(predicted_logit, trg)\n                    val_loss += loss.item()\n                    _, predicted = predicted_logit.max(dim=1)\n                    val_acc += sum(predicted == trg).item() / predicted.size(0)\n        # Finishing iteration\n        if phase == 'valid':\n            val_loss /= len(dataloader_dict['valid'])\n            val_acc /= len(dataloader_dict['valid'])\n            print(\"[Epoch:%d] val_loss:%5.3f | Accuracy:%5.2f | spend_time:%5.2fmin\"\n                    % (e+1, val_loss, val_acc, (time.time() - start_time_e) / 60))\n            if not best_val_loss or val_loss < best_val_loss:\n                print(\"[!] saving model...\")\n                torch.save(model.state_dict(), \n                            os.path.join(save_path, f'model_saved.pt'))\n                best_val_loss = val_loss","execution_count":17,"outputs":[{"output_type":"stream","text":"Model Fitting: [1/10]\n[Epoch:1][0/3000] train_loss:0.678 | Accuracy:0.750 | lr:0.010000 | spend_time: 0.00min\n[Epoch:1][1500/3000] train_loss:0.068 | Accuracy:1.000 | lr:0.010000 | spend_time: 0.13min\n[Epoch:1] val_loss:0.225 | Accuracy: 0.94 | spend_time: 0.32min\n[!] saving model...\nModel Fitting: [2/10]\n[Epoch:2][0/3000] train_loss:0.405 | Accuracy:0.875 | lr:0.010000 | spend_time: 0.00min\n[Epoch:2][1500/3000] train_loss:0.089 | Accuracy:1.000 | lr:0.001000 | spend_time: 0.14min\n[Epoch:2] val_loss:0.230 | Accuracy: 0.94 | spend_time: 0.31min\nModel Fitting: [3/10]\n[Epoch:3][0/3000] train_loss:0.052 | Accuracy:1.000 | lr:0.000100 | spend_time: 0.00min\n[Epoch:3][1500/3000] train_loss:0.052 | Accuracy:1.000 | lr:0.000010 | spend_time: 0.13min\n[Epoch:3] val_loss:0.228 | Accuracy: 0.94 | spend_time: 0.30min\nModel Fitting: [4/10]\n[Epoch:4][0/3000] train_loss:0.066 | Accuracy:1.000 | lr:0.000010 | spend_time: 0.00min\n[Epoch:4][1500/3000] train_loss:0.435 | Accuracy:0.875 | lr:0.000001 | spend_time: 0.14min\n[Epoch:4] val_loss:0.229 | Accuracy: 0.94 | spend_time: 0.33min\nModel Fitting: [5/10]\n[Epoch:5][0/3000] train_loss:0.530 | Accuracy:0.750 | lr:0.000000 | spend_time: 0.00min\n[Epoch:5][1500/3000] train_loss:0.090 | Accuracy:1.000 | lr:0.000000 | spend_time: 0.13min\n[Epoch:5] val_loss:0.228 | Accuracy: 0.94 | spend_time: 0.31min\nModel Fitting: [6/10]\n[Epoch:6][0/3000] train_loss:0.054 | Accuracy:1.000 | lr:0.000000 | spend_time: 0.00min\n[Epoch:6][1500/3000] train_loss:0.778 | Accuracy:0.750 | lr:0.000000 | spend_time: 0.13min\n[Epoch:6] val_loss:0.229 | Accuracy: 0.94 | spend_time: 0.30min\nModel Fitting: [7/10]\n[Epoch:7][0/3000] train_loss:0.079 | Accuracy:1.000 | lr:0.000000 | spend_time: 0.00min\n[Epoch:7][1500/3000] train_loss:0.076 | Accuracy:1.000 | lr:0.000000 | spend_time: 0.13min\n[Epoch:7] val_loss:0.228 | Accuracy: 0.94 | spend_time: 0.31min\nModel Fitting: [8/10]\n[Epoch:8][0/3000] train_loss:0.438 | Accuracy:0.875 | lr:0.000000 | spend_time: 0.00min\n[Epoch:8][1500/3000] train_loss:0.078 | Accuracy:1.000 | lr:0.000000 | spend_time: 0.14min\n[Epoch:8] val_loss:0.228 | Accuracy: 0.94 | spend_time: 0.31min\nModel Fitting: [9/10]\n[Epoch:9][0/3000] train_loss:0.456 | Accuracy:0.875 | lr:0.000000 | spend_time: 0.00min\n[Epoch:9][1500/3000] train_loss:0.303 | Accuracy:0.875 | lr:0.000000 | spend_time: 0.14min\n[Epoch:9] val_loss:0.229 | Accuracy: 0.94 | spend_time: 0.31min\nModel Fitting: [10/10]\n[Epoch:10][0/3000] train_loss:0.386 | Accuracy:0.875 | lr:0.000000 | spend_time: 0.00min\n[Epoch:10][1500/3000] train_loss:0.064 | Accuracy:1.000 | lr:0.000000 | spend_time: 0.13min\n[Epoch:10] val_loss:0.229 | Accuracy: 0.94 | spend_time: 0.31min\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## 10. Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"class CustomDataset_test(Dataset):\n    def __init__(self, src_list, min_len=4, max_len=500):\n        data = src_list\n        self.data = data\n        self.num_data = len(self.data)\n    \n    def __getitem__(self, index):\n        src = self.data[index]\n        return src\n\n    def __len__(self):\n        return self.num_data\n\nclass PadCollate_test:\n    def __init__(self, pad_index=0, dim=0):\n        self.dim = dim\n        self.pad_index = pad_index\n\n    def pad_collate(self, batch):\n        def pad_tensor(vec, max_len, dim):\n            pad_size = list(vec.shape)\n            pad_size[dim] = max_len - vec.size(dim)\n            return torch.cat([vec, torch.LongTensor(*pad_size).fill_(self.pad_index)], dim=dim)\n\n        def pack_sentence(sentences):\n            sentences_len = max(map(lambda x: len(x), sentences))\n            sentences = [pad_tensor(torch.LongTensor(seq), sentences_len, self.dim) for seq in sentences]\n            sentences = torch.cat(sentences)\n            sentences = sentences.view(-1, sentences_len)\n            return sentences\n\n        src = batch\n        return pack_sentence(src)\n\n    def __call__(self, batch):\n        return self.pad_collate(batch)","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dataset_dict = {\n    'test': CustomDataset_test(test_encoded_list, min_len=4, max_len=500)\n}\n\ntest_dataloader_dict = {\n    'test': DataLoader(test_dataset_dict['test'], collate_fn=PadCollate_test(), drop_last=False,\n                        batch_size=batch_size, num_workers=4, shuffle=False, pin_memory=False)\n}\n\nprint(f'Total number of testsets  iterations - {len(test_dataset_dict[\"test\"])}, {len(test_dataloader_dict[\"test\"])}')","execution_count":19,"outputs":[{"output_type":"stream","text":"Total number of testsets  iterations - 375806, 46976\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.eval()\npred=[]\nfor src in test_dataloader_dict['test']:\n    optimizer.zero_grad()\n\n    src = src.to(device)\n    predicted_logit = model(src)\n    _, predicted = predicted_logit.max(dim=1)\n    pred.append(predicted.tolist())","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction = [j for i in pred for j in i]","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction = [0 for i in range(375806)]","execution_count":23,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({\n        \"qid\": test[\"qid\"],\n        \"prediction\": prediction\n    })\nsubmission.to_csv('submission.csv',index=False)","execution_count":24,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"array length 37806 does not match index length 375806","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-6aa312c1c7d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m submission = pd.DataFrame({\n\u001b[1;32m      2\u001b[0m         \u001b[0;34m\"qid\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"qid\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0;34m\"prediction\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     })\n\u001b[1;32m      5\u001b[0m \u001b[0msubmission\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'submission.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[0;34m(data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         ]\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype, verify_integrity)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mextract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    409\u001b[0m                         \u001b[0;34mf\"length {len(index)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m                     )\n\u001b[0;32m--> 411\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m                 \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mibase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: array length 37806 does not match index length 375806"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}